План Экспериментов: Сравнительное Исследование Урезания Архитектур Encoder-only Трансформеров
Общая Цель
Разработать и описать план экспериментов для изучения влияния урезания ключевых параметров архитектуры encoder-only трансформеров (количества attention heads, размерности векторных представлений (embeddings), числа скрытых слоев) на задаче бинарной классификации тональности. Цель — определить, какой из параметров оказывает наибольшее влияние на производительность (качество решения задачи) и эффективность (ресурсоемкость).
Общие Требования и Инструменты

Библиотеки: Использовать экосистему Hugging Face:
transformers для загрузки моделей и токенизаторов.
datasets для загрузки и предобработки данных.
evaluate для расчета стандартных метрик.


Оборудование: Эксперименты рассчитаны на выполнение с использованием GPU Nvidia A40 (48 ГБ VRAM). Учитывать при выборе batch size и использовать смешанную точность (fp16=True) для ускорения и экономии памяти. Использовать SLURM для работы на сервере общего пользования.
Мониторинг: Отслеживать потребление памяти GPU (с помощью GPUtil или nvidia-smi) и время выполнения (обучения и инференса).
Фокус Сравнения: Сравнить влияние урезания каждого параметра (attention heads, vector embeddings, hidden layers) на производительность и эффективность моделей. Оценить компромиссы между качеством и ресурсоемкостью, а также выявить наиболее значимый параметр.


1. Encoder-only Модели: Бинарная Классификация Тональности

Задача: Бинарная классификация тональности текстов (позитивный/негативный). Подходит для encoder-only моделей, так как требует глубокого понимания контекста всего входного текста.
Основной Датасет: IMDb (imdb) – стандартный бенчмарк для классификации отзывов.
Дополнительный Датасет для Дообучения: Yelp Polarity (yelp_polarity) – для оценки адаптации урезанных моделей.
Модели для Сравнения:
bert-base-uncased (110M параметров, 12 слоев, 12 attention heads, 768 embedding size).
roberta-base (125M параметров, 12 слоев, 12 attention heads, 768 embedding size).
distilbert-base-uncased (66M параметров, 6 слоев, 12 attention heads, 768 embedding size).


Эксперименты:
Baseline Fine-tuning:
Тонкая настройка каждой модели на датасете IMDb.
Гиперпараметры (примерные): batch_size=16, epochs=3, learning_rate=5e-5, fp16=True.
Цель: Установить базовую производительность и ресурсоемкость каждой модели на задаче.


Урезание Количества Attention Heads:
Для каждой модели уменьшить количество attention heads с 12 до 6 (num_attention_heads=6).
Повторить fine-tuning на IMDb с теми же гиперпараметрами.
Цель: Оценить влияние уменьшения числа attention heads на производительность и эффективность.


Урезание Размерности Векторных Представлений (Embeddings):
Для каждой модели уменьшить размерность embeddings с 768 до 384 (hidden_size=384).
Убедиться, что размерность feed-forward слоев и другие параметры согласованы (например, intermediate_size=4*hidden_size).
Повторить fine-tuning на IMDb с теми же гиперпараметрами.
Цель: Оценить влияние уменьшения embedding size на производительность и эффективность.


Урезание Числа Скрытых Слоев:
Для bert-base-uncased и roberta-base уменьшить количество слоев с 12 до 6 (num_hidden_layers=6).
Для distilbert-base-uncased уменьшить с 6 до 3 (num_hidden_layers=3).
Повторить fine-tuning на IMDb с теми же гиперпараметрами.
Цель: Оценить влияние уменьшения числа слоев на производительность и эффективность.


Дообучение (Transfer Learning):
Взять каждую урезанную модель (по одному лучшему варианту для каждого типа урезания) и дообучить на датасете Yelp Polarity.
Гиперпараметры (примерные): learning_rate=2e-5, epochs=1-2.
Цель: Оценить, как урезание параметров влияет на способность модели адаптироваться к новому датасету.




Метрики:
Производительность: Accuracy, F1-score (weighted).
Эффективность: Время инференса (мс/пример), Пиковое потребление памяти GPU (ГБ) во время обучения/инференса, Общее время обучения (секунды).




Ожидаемый Результат

Подробное описание плана экспериментов, включая:
Четко определенную задачу (бинарная классификация тональности).
Выбранные модели и датасеты с обоснованием.
Описанные шаги экспериментов (baseline, урезание attention heads, embeddings, hidden layers, дообучение).
Перечень метрик для оценки производительности и эффективности.


Структурированные таблицы для записи и сравнения результатов по всем экспериментам и моделям:

Таблица для IMDb (Baseline и Урезанные Модели)



Model
Config
Accuracy
F1-score
Inference Time (ms)
Memory (GB)
Training Time (s)



BERT-base-uncased
Baseline







BERT-base-uncased
6 Attention Heads







BERT-base-uncased
384 Embedding Size







BERT-base-uncased
6 Hidden Layers







RoBERTa-base
Baseline







RoBERTa-base
6 Attention Heads







RoBERTa-base
384 Embedding Size







RoBERTa-base
6 Hidden Layers







DistilBERT-base-uncased
Baseline







DistilBERT-base-uncased
6 Attention Heads







DistilBERT-base-uncased
384 Embedding Size







DistilBERT-base-uncased
3 Hidden Layers







Таблица для Yelp Polarity (Дообучение)



Model
Config
Accuracy (Yelp)
F1-score (Yelp)
Inference Time (ms)
Memory (GB)
Fine-tuning Time (s)



BERT-base-uncased
Best Reduced Config







RoBERTa-base
Best Reduced Config







DistilBERT-base-uncased
Best Reduced Config








Анализ ожидаемых результатов:
Урезание attention heads может снизить способность модели улавливать сложные зависимости, но уменьшит потребление памяти.
Уменьшение embedding size сократит общее количество параметров, что может существенно снизить ресурсоемкость, но потенциально ухудшит качество представлений.
Уменьшение числа слоев упростит модель, что ускорит обучение и инференс, но может ограничить глубину обработки контекста.
Наиболее значимый параметр будет определен по степени ухудшения метрик (Accuracy, F1-score) при минимальном снижении эффективности.



